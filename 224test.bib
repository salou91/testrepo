@BOOK{Alemi2019,
  title     = {The amazing journey of reason: From {DNA} to artificial
               intelligence},
  author    = {Alemi, Mario},
  publisher = {Springer Nature},
  location  = {Cham, Switzerland},
  edition   = {1},
  date      = {2019-12-07},
  pagetotal = {113},
  isbn      = {9783030259617,9783030259624},
  abstract  = {The Amazing Journey analyzes the latest results in chemistry,
               biology, neuroscience, anthropology and sociology under the light
               of the evolution of intelligence, seen as the ability of
               processing information.},
  series    = {SpringerBriefs in Computer Science},
  keywords  = {programming},
  language  = {en}
}

@ARTICLE{Miyagawa2023,
  title        = {The ratio of circulating eicosapentaenoic acid to arachidonic
                  acid ratio in the community-dwelling Japanese population},
  author       = {Miyagawa, Naoko},
  journaltitle = {J. Atheroscler. Thromb.},
  publisher    = {Japan Atherosclerosis Society},
  volume       = {30},
  issue        = {6},
  pages        = {587--588},
  date         = {2023-06-01},
  abstract     = {The Ratio of Circulating Eicosapentaenoic Acid to Arachidonic
                  Acid Ratio in the Community-Dwelling Japanese Population},
  urldate      = {2024-04-29},
  note         = {2002},
  keywords     = {programming},
  language     = {en}
}

@ARTICLE{Nelson2017,
  title        = {Potential benefits of eicosapentaenoic acid on atherosclerotic
                  plaques},
  author       = {Nelson, J R and Wani, O and May, H T and Budoff, M},
  journaltitle = {Vascul. Pharmacol.},
  publisher    = {Vascul Pharmacol},
  volume       = {91},
  pages        = {1--9},
  date         = {2017-04},
  abstract     = {Residual cardiovascular (CV) risk remains in some patients
                  despite optimized statin therapy and may necessitate add-on
                  therapy to reduce this risk. Eicosapentaenoic acid (EPA), an
                  omega-3 polyunsaturated fatty acid, lowers plasma triglyceride
                  levels without raising low-density lipoprotein cholesterol
                  levels and has potential beneficial effects on atherosclerotic
                  plaques. Animal studies have shown that EPA reduces levels of
                  pro-inflammatory cytokines and chemokines. In clinical trials
                  utilizing a wide spectrum of plaque imaging modalities, EPA
                  has shown beneficial effects on plaque characteristics.
                  Studies of patients with coronary artery disease receiving
                  statin therapy suggest that EPA may decrease plaque
                  vulnerability and prevent plaque progression. EPA also
                  decreased pentraxin-3 and macrophage accumulation. A large,
                  randomized, Japanese study reported that EPA plus a statin
                  resulted in a 19\% relative reduction in major coronary events
                  at 5years versus a statin alone in patients with
                  hypercholesterolemia (P=0.011). Icosapent ethyl, a high-purity
                  prescription form of EPA ethyl ester, has been shown to reduce
                  triglyceride levels and markers of atherosclerotic
                  inflammation. Results of an ongoing CV outcomes study will
                  further define the potential clinical benefits of icosapent
                  ethyl in reducing CV risk in high-risk patients receiving
                  statin therapy.},
  urldate      = {2024-04-29},
  keywords     = {Atherosclerosis; Atherosclerotic plaque; Eicosapentaenoic
                  acid; Eicosapentaenoic acid ethyl ester; Omega-3 fatty
                  acids;programming},
  language     = {en}
}

@MISC{temporaryCitekey-pboxz,
  title       = {Tunnel Try-on: Excavating Spatial-temporal Tunnels for
                 High-quality Virtual Try-on in Videos},
  author      = {Xu, Zhengze and Chen, Mengting and Wang, Zhao and Xing, Linyu
                 and Zhai, Zhonghua and Sang, Nong and Lan, Jinsong and Xiao,
                 Shuai and Gao, Changxin},
  date        = {2024-04-26},
  eprintclass = {cs.CV},
  abstract    = {Video try-on is a challenging task and has not been well
                 tackled in previous works. The main obstacle lies in preserving
                 the details of the clothing and modeling the coherent motions
                 simultaneously. Faced with those difficulties, we address video
                 try-on by proposing a diffusion-based framework named "Tunnel
                 Try-on." The core idea is excavating a "focus tunnel" in the
                 input video that gives close-up shots around the clothing
                 regions. We zoom in on the region in the tunnel to better
                 preserve the fine details of the clothing. To generate coherent
                 motions, we first leverage the Kalman filter to construct
                 smooth crops in the focus tunnel and inject the position
                 embedding of the tunnel into attention layers to improve the
                 continuity of the generated videos. In addition, we develop an
                 environment encoder to extract the context information outside
                 the tunnels as supplementary cues. Equipped with these
                 techniques, Tunnel Try-on keeps the fine details of the
                 clothing and synthesizes stable and smooth videos.
                 Demonstrating significant advancements, Tunnel Try-on could be
                 regarded as the first attempt toward the commercial-level
                 application of virtual try-on in videos.},
  urldate     = {2024-04-29},
  note        = {2024},
  keywords    = {programming}
}

@MISC{temporaryCitekey-yknhp,
  title       = {{MaPa}: Text-driven Photorealistic Material Painting for {3D}
                 Shapes},
  author      = {Zhang, Shangzhan and Peng, Sida and Xu, Tao and Yang, Yuanbo
                 and Chen, Tianrun and Xue, Nan and Shen, Yujun and Bao, Hujun
                 and Hu, Ruizhen and Zhou, Xiaowei},
  date        = {2024-04-26},
  eprintclass = {cs.CV},
  abstract    = {This paper aims to generate materials for 3D meshes from text
                 descriptions. Unlike existing methods that synthesize texture
                 maps, we propose to generate segment-wise procedural material
                 graphs as the appearance representation, which supports
                 high-quality rendering and provides substantial flexibility in
                 editing. Instead of relying on extensive paired data, i.e., 3D
                 meshes with material graphs and corresponding text
                 descriptions, to train a material graph generative model, we
                 propose to leverage the pre-trained 2D diffusion model as a
                 bridge to connect the text and material graphs. Specifically,
                 our approach decomposes a shape into a set of segments and
                 designs a segment-controlled diffusion model to synthesize 2D
                 images that are aligned with mesh parts. Based on generated
                 images, we initialize parameters of material graphs and
                 fine-tune them through the differentiable rendering module to
                 produce materials in accordance with the textual description.
                 Extensive experiments demonstrate the superior performance of
                 our framework in photorealism, resolution, and editability over
                 existing methods. Project page:
                 https://zhanghe3z.github.io/MaPa/},
  urldate     = {2024-04-29},
  note        = {2024},
  keywords    = {programming}
}

@MISC{temporaryCitekey-znuvb,
  title       = {{ChangeBind}: A Hybrid Change Encoder for Remote Sensing Change
                 Detection},
  author      = {Noman, Mubashir and Fiaz, Mustansar and Cholakkal, Hisham},
  date        = {2024-04-26},
  eprintclass = {cs.CV},
  abstract    = {Change detection (CD) is a fundamental task in remote sensing
                 (RS) which aims to detect the semantic changes between the same
                 geographical regions at different time stamps. Existing
                 convolutional neural networks (CNNs) based approaches often
                 struggle to capture long-range dependencies. Whereas recent
                 transformer-based methods are prone to the dominant global
                 representation and may limit their capabilities to capture the
                 subtle change regions due to the complexity of the objects in
                 the scene. To address these limitations, we propose an
                 effective Siamese-based framework to encode the semantic
                 changes occurring in the bi-temporal RS images. The main focus
                 of our design is to introduce a change encoder that leverages
                 local and global feature representations to capture both subtle
                 and large change feature information from multi-scale features
                 to precisely estimate the change regions. Our experimental
                 study on two challenging CD datasets reveals the merits of our
                 approach and obtains state-of-the-art performance.},
  urldate     = {2024-04-29},
  note        = {2024},
  keywords    = {programming}
}
